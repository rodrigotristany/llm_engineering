{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b0e11f2-9ea4-48c2-b8d2-d0a4ba967827",
   "metadata": {},
   "source": [
    "# ¡Día de Gradio!\n",
    "\n",
    "Hoy crearemos interfaces de usuario utilizando el increíblemente simple marco Gradio.\n",
    "\n",
    "## ¡Prepárate para la alegría!\n",
    "\n",
    "Ten en cuenta que las pantallas de Gradio pueden aparecer en \"modo oscuro\" o \"modo claro\" según la configuración de tu computadora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c44c5494-950d-4d2f-8d4f-b87b57c5b330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1715421-cead-400b-99af-986388a97aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr # oh yeah!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337d5dfc-0181-4e3b-8ab9-e78e0c3f657b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key existe y empieza por sk-proj-\n",
      "Anthropic API Key existe y empieza por sk-ant-\n",
      "Google API Key existe y empieza por AIzaSyBr\n"
     ]
    }
   ],
   "source": [
    "# Cargar variables de entorno en un archivo llamado .env\n",
    "# Imprimir los prefijos de clave para facilitar la depuración\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key existe y empieza por {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key Sin Configurar\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key existe y empieza por {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key Sin Configurar\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key existe y empieza por {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key Sin Configurar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22586021-1795-4929-8079-63f5bb4edd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conéctese a OpenAI, Anthropic y Google; comente las líneas de Claude o Google si no las está usando\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "#claude = anthropic.Anthropic()\n",
    "\n",
    "# google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b16e6021-6dc4-4397-985a-6679d6c8ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un mensaje genérico del sistema: ¡no más IA adversarias sarcásticas!\n",
    "\n",
    "system_message = \"Eres un asistente útil\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02ef9b69-ef31-427d-86d0-b8c799e1c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Envolvamos una llamada a GPT-4o-mini en una función simple\n",
    "\n",
    "def message_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    completion = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=messages,\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef7d314-2b13-436b-b02d-8de3b72b193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_gpt(\"¿Cual es la fecha de hoy?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94013d1-4f27-4329-97e8-8c58db93636a",
   "metadata": {},
   "source": [
    "## Momento de crear nuestra interfaz de usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc664b7a-c01d-4fea-a1de-ae22cdd5141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí hay una función simple\n",
    "\n",
    "def shout(text):\n",
    "    print(f\"Has llamado a la función shout con el mensaje: {text}\")\n",
    "    return text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ea451-d3a0-4d13-b599-93ed49b975e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shout(\"Hola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f1f15a-122e-4502-b112-6ee2817dda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La simplicidad de Gradio. Esto puede aparecer en \"modo claro\". Más adelante te mostraré cómo hacerlo en modo oscuro.\n",
    "\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a359a4-685c-4c99-891c-bb4d1cb7f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar share=True significa que se puede acceder a él de forma pública\n",
    "# Hay disponible un alojamiento más permanente mediante una plataforma llamada Spaces de HuggingFace,\n",
    "# que abordaremos la próxima semana\n",
    "\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd87533a-ff3a-4188-8998-5bedd5ba2da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar inbrowser=True abre una nueva ventana del navegador automáticamente\n",
    "\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42ec007-0314-48bf-84a4-a65943649215",
   "metadata": {},
   "source": [
    "## Forzar el modo oscuro\n",
    "\n",
    "Gradio aparece en modo claro o en modo oscuro según la configuración del navegador y la computadora. Hay una manera de forzar que Gradio aparezca en modo oscuro, pero Gradio recomienda no hacerlo ya que debería ser una preferencia del usuario (particularmente por razones de accesibilidad). Pero si desea forzar el modo oscuro para sus pantallas, a continuación se muestra cómo hacerlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8129afa-532b-4b15-b93c-aa9cca23a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define esta variable y luego pasa js=force_dark_mode al crear la interfaz\n",
    "\n",
    "force_dark_mode = \"\"\"\n",
    "function refresh() {\n",
    "    const url = new URL(window.location);\n",
    "    if (url.searchParams.get('__theme') !== 'dark') {\n",
    "        url.searchParams.set('__theme', 'dark');\n",
    "        window.location.href = url.href;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\", js=force_dark_mode).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc67b26-dd5f-406d-88f6-2306ee2950c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entradas y Salidas\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=shout,\n",
    "    inputs=[gr.Textbox(label=\"Tu Mensaje:\", lines=6)],\n",
    "    outputs=[gr.Textbox(label=\"Respuesta:\", lines=8)],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f235288e-63a2-4341-935b-1441f9be969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y ahora, cambiando la función de \"shout\" a \"message_gpt\"\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=message_gpt,\n",
    "    inputs=[gr.Textbox(label=\"Tu Mensaje:\", lines=6)],\n",
    "    outputs=[gr.Textbox(label=\"Respuesta:\", lines=8)],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9a3262-e626-4e4b-80b0-aca152405e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usemos Markdown\n",
    "# ¿Te preguntas por qué es importante configurar system_message cuando no se hace referencia a él en el código que se encuentra debajo?\n",
    "# Estoy aprovechando que system_message es una variable global, que se usa en la función message_gpt (échale un vistazo)\n",
    "# No es una gran práctica de ingeniería de software, pero es bastante común durante la investigación y el desarrollo de Jupyter Lab.\n",
    "\n",
    "system_message = \"Eres una asistente útil que responde en formato markdown\"\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=message_gpt,\n",
    "    inputs=[gr.Textbox(label=\"Tu mensaje:\")],\n",
    "    outputs=[gr.Markdown(label=\"Respuesta:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c04ebf-0671-4fea-95c9-bc1565d4bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a crear una llamada que transmita resultados\n",
    "# Si deseas un repaso de los generadores (la palabra clave \"yield\"),\n",
    "# Echa un vistazo al cuaderno de Python intermedio en la carpeta de la semana 1.\n",
    "\n",
    "\n",
    "def stream_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    stream = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb1f789-ff11-4cba-ac67-11b815e29d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_gpt,\n",
    "    inputs=[gr.Textbox(label=\"Tu :\")],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc8e930-ba2a-4194-8f7c-044659150626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_claude(prompt):\n",
    "    result = claude.messages.stream(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0.7,\n",
    "        system=system_message,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    response = \"\"\n",
    "    with result as stream:\n",
    "        for text in stream.text_stream:\n",
    "            response += text or \"\"\n",
    "            yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0066ffd-196e-4eaf-ad1e-d492958b62af",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_claude,\n",
    "    inputs=[gr.Textbox(label=\"Tu Mensaje:\")],\n",
    "    outputs=[gr.Markdown(label=\"Respuesta:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5a70b9-2afe-4a7c-9bed-2429229e021b",
   "metadata": {},
   "source": [
    "## Una mejora menor\n",
    "\n",
    "He realizado una pequeña mejora en este código.\n",
    "\n",
    "Anteriormente, tenía estas líneas:\n",
    "\n",
    "```\n",
    "for chunk in result:\n",
    "yield chunk\n",
    "```\n",
    "\n",
    "En realidad, hay una forma más elegante de lograr esto (que los expertos en Python podrían llamar más \"Pythonico\"):\n",
    "\n",
    "`yield from result`\n",
    "\n",
    "Abordo esto con más detalle en el cuaderno de Python intermedio en la carpeta week1; échale un vistazo si quieres más información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0087623a-4e31-470b-b2e6-d8d16fc7bcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_model(prompt, model):\n",
    "    if model==\"GPT\":\n",
    "        result = stream_gpt(prompt)\n",
    "    elif model==\"Claude\":\n",
    "        result = stream_claude(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Modelo Desconocido\")\n",
    "    yield from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8ce810-997c-4b6a-bc4f-1fc847ac8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_model,\n",
    "    inputs=[gr.Textbox(label=\"Tu mensaje:\"), gr.Dropdown([\"GPT\", \"Claude\"], label=\"Selecciona un modelo:\", value=\"GPT\")],\n",
    "    outputs=[gr.Markdown(label=\"Respuesta:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933865b-654c-4b92-aa45-cf389f1eda3d",
   "metadata": {},
   "source": [
    "# Cómo crear un generador de folletos de empresa\n",
    "\n",
    "Ahora ya sabes cómo hacerlo: ¡es muy sencillo!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d7c49b-2e0e-45b3-92ce-93ca9f962ef4",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "<tr>\n",
    "<td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "<img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "</td>\n",
    "<td>\n",
    "<h2 style=\"color:#900;\">Antes de leer las próximas celdas</h2>\n",
    "<span style=\"color:#900;\">\n",
    "Intente hacerlo usted mismo: vuelva al folleto de la empresa en la semana 1, día 5 y agregue una interfaz de usuario de Gradio al final. Luego, venga y observe la solución.\n",
    "</span>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1626eb2e-eee8-4183-bda5-1591b58ae3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una clase para representar una página web\n",
    "\n",
    "class Website:\n",
    "    url: str\n",
    "    title: str\n",
    "    text: str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No se ha encontrado título de la página\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Título de la Web:\\n{self.title}\\nContenido de la Web:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c701ec17-ecd5-4000-9f68-34634c8ed49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¡Muchas gracias a Bill G., que se dio cuenta de que una versión anterior de este programa tenía un error! Ya está corregido.\n",
    "\n",
    "system_message = \"Eres un asistente que analiza el contenido de la página de inicio \\\n",
    "del sitio web de una empresa y crea un folleto breve sobre la empresa para posibles clientes, inversores y nuevos empleados.\\\n",
    "Responde en formato Markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5def90e0-4343-4f58-9d4a-0e36e445efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url, model):\n",
    "    prompt = f\"Genera un folleto de la empresa {company_name}. Esta es su página de destino:\\n\"    \n",
    "    prompt += Website(url).get_contents()\n",
    "    if model==\"GPT\":\n",
    "        result = stream_gpt(prompt)\n",
    "    elif model==\"Claude\":\n",
    "        result = stream_claude(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Modelo Desconocido\")\n",
    "    yield from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66399365-5d67-4984-9d47-93ed26c0bd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_brochure,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Nombre de la Empresa:\"),\n",
    "        gr.Textbox(label=\"Landing page, recuerda incluir http:// o https://\"),\n",
    "        gr.Dropdown([\"GPT\", \"Claude\"], label=\"Selecciona un modelo\")],\n",
    "    outputs=[gr.Markdown(label=\"Folleto:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ede97ca3-a0f8-4f6e-be17-d1de7fef9cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cold\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "genai.configure(api_key=google_api_key)\n",
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "response = model.generate_content(\"The opposite of hot is\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac694d6-6deb-47e8-9421-d1d51a6d99b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
