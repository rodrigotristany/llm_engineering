{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e2ef28-594f-4c18-9d22-c6b8cd40ead2",
   "metadata": {},
   "source": [
    "# Día 3 – IA conversacional – ¡también conocido como Chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70e39cd8-ec79-4e3e-9c26-5659d42d0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "231605aa-fccb-447e-89cf-8b187444536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key existe y empieza por sk-proj-\n",
      "Anthropic API Key existe y empieza por sk-ant-\n",
      "Google API Key existe y empieza por AIzaSyBr\n"
     ]
    }
   ],
   "source": [
    "# Cargar variables de entorno en un archivo llamado .env\n",
    "# Imprimir los prefijos de clave para facilitar la depuración\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key existe y empieza por {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key Sin Configurar\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key existe y empieza por {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key Sin Configurar\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key existe y empieza por {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key Sin Configurar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6541d58e-2297-4de1-b1f7-77da1b98b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar\n",
    "\n",
    "openai = OpenAI()\n",
    "MODEL = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e16839b5-c03b-4d9d-add6-87a0f6f37575",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"Eres un assistente muy útil\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e97227-f162-4d1a-a0b2-345ff248cbe7",
   "metadata": {},
   "source": [
    "# La estructura interna del historial de mensajes\n",
    "\n",
    "Originalmente, gradio esperaba recibir una función llamada:\n",
    "\n",
    "`chat(message, history)`\n",
    "\n",
    "La cual debía recibir `history` en un formato particular, que debemos asignar al formato OpenAI antes de llamar a OpenAI:\n",
    "\n",
    "```\n",
    "[\n",
    "{\"role\": \"system\", \"content\": \"system message here\"},\n",
    "{\"role\": \"user\", \"content\": \"first user prompt here\"},\n",
    "{\"role\": \"assistant\", \"content\": \"the assistant's response\"},\n",
    "{\"role\": \"user\", \"content\": \"the new user prompt\"},\n",
    "]\n",
    "```\n",
    "\n",
    "¡Pero Gradio se ha actualizado! Ahora pasará `history` en el formato exacto de OpenAI, perfecto para que lo enviemos directamente a OpenAI.\n",
    "\n",
    "¡Así que nuestro trabajo se volvió más fácil!\n",
    "\n",
    "Escribiremos una función `chat(message, history)` donde:\n",
    "**message** es el mensaje que se debe usar\n",
    "**history** es la conversación anterior, en formato OpenAI\n",
    "\n",
    "Combinaremos el mensaje del sistema, el historial y el último mensaje, y luego llamaremos a OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eacc8a4-4b48-4358-9e06-ce0020041bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¡Ahora es solo una línea de código para preparar la entrada a OpenAI!\n",
    "\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    print(\"El historial es:\")\n",
    "    print(history)\n",
    "    print(\"Y los mensajes son:\")\n",
    "    print(messages)\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1334422a-808f-4147-9c4c-57d63d9780d0",
   "metadata": {},
   "source": [
    "## ¡Y entonces entra la magia de Gradio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0866ca56-100a-44ab-8bd0-1568feaf6bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El historial es:\n",
      "[]\n",
      "Y los mensajes son:\n",
      "[{'role': 'system', 'content': 'Eres un assistente muy útil'}, {'role': 'user', 'content': '¿Cómo puedo llegar a el Obelisco en Buenos Aires?'}]\n",
      "El historial es:\n",
      "[{'role': 'user', 'metadata': {'title': None}, 'content': '¿Cómo puedo llegar a el Obelisco en Buenos Aires?', 'options': None}, {'role': 'assistant', 'metadata': {'title': None}, 'content': 'Para llegar al Obelisco en Buenos Aires, tienes varias opciones, dependiendo de tu ubicación y preferencias de transporte. Aquí te doy algunas recomendaciones:\\n\\n### Transporte público\\n1. **Colectivo (autobús)**: Hay varias líneas de colectivos que pasan por la Avenida 9 de Julio, donde se encuentra el Obelisco. Las líneas más comunes son las que van por la 9 de Julio, como la 5, 6, 9, 19, 70, 100, entre otras.\\n\\n2. **Subte (metro)**: La estación de metro más cercana es \"Catedral\" (Línea D, color verde) que está a unas pocas cuadras del Obelisco. También puedes utilizar la estación \"9 de Julio\" (Línea B, color rojo) que te permitirá acceder a la Avenida 9 de Julio.\\n\\n3. **Tren**: Si vienes desde el conurbano, puedes tomar un tren hasta la estación \"Constitución\" o \"Retiro\" y luego hacer un transbordo a colectivo o caminar hasta el Obelisco, que está relativamente cerca.\\n\\n### Transporte privado\\n1. **Taxi o ridesharing**: Puedes solicitar un taxi o utilizar aplicaciones como Uber o Cabify para llegar al Obelisco fácilmente.\\n\\n2. **Auto**: Si decides ir en coche, hay varias calles que llevan al centro de la ciudad. Sin embargo, debes tener en cuenta el tráfico y la disponibilidad de estacionamiento.\\n\\n### A pie\\nSi ya estás en el centro de Buenos Aires, el Obelisco es bastante accesible a pie, ya que se encuentra en una ubicación céntrica.\\n\\nRecuerda verificar las condiciones del tráfico y la disponibilidad de transporte en el momento de tu viaje. ¡Buen viaje!', 'options': None}]\n",
      "Y los mensajes son:\n",
      "[{'role': 'system', 'content': 'Eres un assistente muy útil'}, {'role': 'user', 'metadata': {'title': None}, 'content': '¿Cómo puedo llegar a el Obelisco en Buenos Aires?', 'options': None}, {'role': 'assistant', 'metadata': {'title': None}, 'content': 'Para llegar al Obelisco en Buenos Aires, tienes varias opciones, dependiendo de tu ubicación y preferencias de transporte. Aquí te doy algunas recomendaciones:\\n\\n### Transporte público\\n1. **Colectivo (autobús)**: Hay varias líneas de colectivos que pasan por la Avenida 9 de Julio, donde se encuentra el Obelisco. Las líneas más comunes son las que van por la 9 de Julio, como la 5, 6, 9, 19, 70, 100, entre otras.\\n\\n2. **Subte (metro)**: La estación de metro más cercana es \"Catedral\" (Línea D, color verde) que está a unas pocas cuadras del Obelisco. También puedes utilizar la estación \"9 de Julio\" (Línea B, color rojo) que te permitirá acceder a la Avenida 9 de Julio.\\n\\n3. **Tren**: Si vienes desde el conurbano, puedes tomar un tren hasta la estación \"Constitución\" o \"Retiro\" y luego hacer un transbordo a colectivo o caminar hasta el Obelisco, que está relativamente cerca.\\n\\n### Transporte privado\\n1. **Taxi o ridesharing**: Puedes solicitar un taxi o utilizar aplicaciones como Uber o Cabify para llegar al Obelisco fácilmente.\\n\\n2. **Auto**: Si decides ir en coche, hay varias calles que llevan al centro de la ciudad. Sin embargo, debes tener en cuenta el tráfico y la disponibilidad de estacionamiento.\\n\\n### A pie\\nSi ya estás en el centro de Buenos Aires, el Obelisco es bastante accesible a pie, ya que se encuentra en una ubicación céntrica.\\n\\nRecuerda verificar las condiciones del tráfico y la disponibilidad de transporte en el momento de tu viaje. ¡Buen viaje!', 'options': None}, {'role': 'user', 'content': 'Yo me encuentro en Salta capital'}]\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f91b414-8bab-472d-b9c9-3fa51259bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"Eres un asistente útil en una tienda de ropa. \\\n",
    "Debes tratar de alentar gentilmente al cliente a que pruebe los artículos que están en oferta.\\\n",
    "Los sombreros tienen un 60 % de descuento y la mayoría de los demás artículos tienen un 50 % de descuento. \\\n",
    "Por ejemplo, si el cliente dice 'Quiero comprar un sombrero', \\\n",
    "podrías responder algo como 'Genial, tenemos muchos sombreros, incluidos varios que son parte de nuestro evento de rebajas'. \\\n",
    "Anima al cliente a comprar sombreros si no está seguro de qué comprar.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e5be3ec-c26c-42bc-ac16-c39d369883f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "413e9e4e-7836-43ac-a0c3-e1ab5ed6b136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d75f0ffa-55c8-4152-b451-945021676837",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message += \"\\nSi el cliente pide zapatos, debes responder que los zapatos no están en oferta hoy, \\\n",
    "¡pero recuérdale al cliente que mire los sombreros!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c602a8dd-2df7-4eb7-b539-4e01865a6351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a987a66-1061-46d6-a83a-a30859dc88bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    if 'cinturon' in message:\n",
    "        messages.append({\"role\": \"system\", \"content\": \"Para mayor contexto, la tienda no vende cinturones,\\\n",
    "        pero asegúrate de señalar otros artículos en oferta.\"})\n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20570de2-eaad-42cc-a92c-c779d71b48b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a57ee0-b945-48a7-a024-01b56a5d4b3e",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "<tr>\n",
    "<td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "<img src=\"../business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "</td>\n",
    "<td>\n",
    "<h2 style=\"color:#181;\">Aplicaciones empresariales</h2>\n",
    "<span style=\"color:#181;\">Los asistentes conversacionales son, por supuesto, un caso de uso muy común para la IA de última generación, y los últimos modelos de vanguardia son notablemente buenos para conversaciones matizadas. Y Gradio facilita la creación de una interfaz de usuario. Otra habilidad crucial que cubrimos es cómo usar indicaciones para brindar contexto, información y ejemplos.\n",
    "<br/><br/>\n",
    "Piense en cómo podría aplicar un asistente de IA a su negocio y cree un prototipo. Utilice el mensaje del sistema para contextualizar su negocio y establecer el tono para el LLM.</span>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb9e21-df67-4c2b-b952-5e7e7961b03d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
